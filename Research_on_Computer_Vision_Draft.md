# Research on Computer Vision

List of definitions before work.

1. Artificial Intelligence (AI)
2. Machine Learning (ML)
3. Neural Network



## Introduction ..

A very compelling type artificial intelligence is that of the Computer Vision. Within the field of Artificial intelligence, Computer Vision is a sub field which deals with the identification, recognition and derivation of meaningful information from digital images and video data by teaching models and neural networks to accomplish this specific goals[1].

The human eye over the years with training would be able to tell objects apart by their distinct characteristics and features. It is able to tell the distance from an object or whether an object is moving or still.
Computer vision with a lot of data are trained to do the same thing a human eye would be capable of doing with greater precision and in faster time with image data from cameras and algorithms to surpass that of the human capabilities. This systems have wide area of usage in the industries i.e manufacturing to the automotive industry and growing - the market is valued to be at about USD 20.31 billion expected to grow to about USD 175.72 billion by 2032. [3]


## Definition ...

Computer Vision is a specialised field under Artificial intelligence that focuses on enabling machine to understand the visual world around them through the use of digital image and video data from cameras and deep learning. [2]
It focuses on replicating the complex function of recognition  of the human eye in machines allowing them to produce information from processing visual data (images and videos)


3. ---- Architecture 

	[ A very important aspect to the architecture of computer vision is the area of Deep learning. With the advancement of machine learning and neural networks in the recent years the area of computer vision has seen great leaps in achievements even surpassing humans in some tasks of accurate detection and recognition. ]
	
## Architecture ..
A great deal of computer vision is identifying and understanding patterns from visual data, but before this can be archived the model would have to be trained just like a human would have to be trained to distinguish between different visual data. This training would require a lot of data which could already have been labeled, [7].
To understand this image data being passed, the data would have to be analyzed because at its lowest level, computers only understand 1's and 0'. Convolutional neural networks help ML models see by fractionating images into pixels. Each pixel is given a label or tag to produce a matrix of this labels that the system can now interpret.
These labels are then collectively used to carry out convolutions, a mathematical process that combines two functions to produce a third function. Through this process, convolutional neural networks can process visual inputs. [11]
The model would have to run analysis of data repeatedly till it can recognise patterns and distinctions between them to match the label as accurately as possible.

Typically Computer Vision would be handled in the following steps:
1. Acquiring training data (Images and Videos) [2].
2. Processing the data [2].
3. Understanding the data processed to acquire meaningfully information [2].
	
### Computer Vision and Deep Learning: .
	Deep Learning:
	Deep learning is a subset of Machine learning (ML) where the complex decision-making power of the human brain is simulated with deep neural network which are multi-layered neural network. [6] UNFINISHED
	
	


## Case Study

One of the very important application of Computer Vision is object detection. At this use case, the goal is to precisely  locate object of interest in an image or video. The task would be to identify the position and boundaries of objects in images or videos. [8, 9]
One real world application of this model would be Google translate.

_Google translate:_

This is an online service developed and provided by Google that allows a variety of translation services supporting over 100 languages using Neural Machine models for detection to precisely translate between languages and improve it self over time.
Visual Text translation offered by google translate uses Computer vision at it's core implementation, this done by the visual identification of the text character and precise handling of the information to give the end user a proper interpretation of the input data. Due to improvement in deep learning algorithms like convolutional neural networks google translate can not only detect an identify a dog in a picture but at it's currently trained level it is even able to detect and identify different dog breeds which older models would struggle to handle. [10]

#### Google translate working -- [fix heading]

The process of google translate identifying and accurately translating data for the user, a number of steps would taken to archive this.

1. Firstly, when the image is passed, google translate app tries to identify important parts of the image that might hold text to be translated, this involves looking for blobs of pixel that have similar color and near other similar blobs. This blobs searched would also be checked if they could be in a line so we can continuously read them.

2. After this blobs are read this is where google translate has to try recognizing what each letter actually is. This is done using the deep learning model, convolutional neural network. This network has been trained to accurately identify what different letters look like. This model has not just been trained on "precise-looking" letter images cause in the real world we'd be encountering all sort of dirty smudges or images marred by reflection, So to handle this cases the network was trained data generated by google to mimic this smudges and dirt that the real world input would include.

3. Knowing that the previous steps could potentially contain errors from recognition, the dictionary look-up of this recognised words would only be an approximation. Using this method, if an 'S' was read as '5' then the approximate word '5uper' would still be able to be looked up.

4. Finally the words translated from the dictionary look-up would be passed to the user either read-out or rendered to screen as the final result from all the computation of the previous steps.














`Draft`
3. architecture, .
4. models/techniques/algorithms used in those topics listed,
5. Prese√±t a case study used in the topic, 
6. give us the possibilities and challenges on the topics then provide a conclusion and recommendations on them, 

